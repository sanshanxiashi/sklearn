import pandas as pd
from sklearn import preprocessing
from sklearn.svm import SVR

origin = '/home/hadoop/git/learn_sklearn/sklearn/out.csv'
#读数据
data = pd.read_csv(origin)	
	
	#数据描述
	data.describe()
	
my_X = data.iloc[:,:27].as_matrix()
my_y = data.iloc[:,27].as_matrix()
	X = data.iloc[:,[0,1,3,4,5,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26]].as_matrix()
	y = data.iloc[:,27].as_matrix()

#标准化        
scaler = preprocessing.StandardScaler().fit(my_X) 
X = scaler.transform(my_X)
y = my_y

#训练svr
  svr_rbf = SVR(kernel='rbf', C=1e3, gamma=0.1)
  y_rbf = svr_rbf.fit(X[0:22300], y[0:22300])
  y_pred = y_rbf.predict(X[22300:27879])
  y_true = y[22300:27879]
 
#score
  score1 = svr_rbf.score(X[0:22300], y[0:22300])
  score2 = svr_rbf.score(X[22300:27879], y[22300:27879])


#训练 gbrt
 (1)
 params = {'n_estimators': 500, 'max_depth': 4, 'min_samples_split': 2, 'learning_rate': 0.01, 'loss': 'ls'}
 clf = ensemble.GradientBoostingRegressor(**params)
 y_gbrt = clf.fit(X[0:22300], y[0:22300])
 y_pred2 = y_gbrt.predict(X[22300:27879])

 score3 = clf.score(X[0:22300], y[0:22300])
 score4 = clf.score(X[22300:27879], y[22300:27879])

 from sklearn.metrics import mean_absolute_error
 y_true = y[22300:27879]
 mae = mean_absolute_error(y_true, y_pred2)
 #2.7504

 from sklearn.metrics import mean_squared_error
 mse = mean_squared_error(y_true, y_pred2)
 #23.37570

  clf.feature_importances_

 (2)
 params = {'n_estimators': 1000, 'max_depth': 6, 'min_samples_split': 2, 'learning_rate': 0.01, 'loss': 'ls'}
 y_gbrt = clf.fit(X[0:22300], y[0:22300])
 y_pred3 = y_gbrt.predict(X[22300:27879])
 mae3= 2.806

 (3)
 params = {'n_estimators': 1000, 'max_depth':8, 'min_samples_split': 2, 'learning_rate': 0.01, 'loss': 'ls'}
 y_gbrt = clf.fit(X[0:22300], y[0:22300])
 y_pred4 = y_gbrt.predict(X[22300:27879])
 mae4
